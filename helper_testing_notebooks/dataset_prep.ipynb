{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create single script that will process whole dataset in single pass\n",
    "\n",
    "- Remove limb from continuum images\n",
    "- normalize\n",
    "- enhance\n",
    "- normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sunpy.map\n",
    "from astropy import units as u\n",
    "import sunpy.coordinates.transformations\n",
    "from sunpy.coordinates import frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array for holding limb darkening coef\n",
    "# 6205.90 A\n",
    "coef_limb_hmi = np.array(\n",
    "    [0.32519, 1.26432, -1.44591, 1.55723, -0.87415, 0.173333])\n",
    "\n",
    "\n",
    "def limb_dark(r, koef=coef_limb_hmi):\n",
    "    # r is normalized distance from center [0,1]\n",
    "    if len(koef) != 6:\n",
    "        raise ValueErrror(\"koef len should be exactly 6\")\n",
    "    if np.max(r) > 1 or np.min(r) < 0:\n",
    "        raise ValueError(\"r should be in [0,1] range\")\n",
    "    mu = np.sqrt(1-r**2)  # mu = cos(theta)\n",
    "    return koef[0]+koef[1]*mu+koef[2]*mu**2+koef[3]*mu**3+koef[4]*mu**4+koef[5]*mu**5\n",
    "\n",
    "\n",
    "def correct_for_limb(sunpy_map):\n",
    "    '''\n",
    "    This function takes sunpy map and removes limb darkening from it\n",
    "    It transfer coordinate mesh to helioprojective coordinate (using data from header)\n",
    "    Calucalates distance from sun center in units of sun radii at the time of observation\n",
    "    Uses limb_dark function with given coeffitiens and divides by that value\n",
    "\n",
    "    Input: sunpy_map (sunpy.map) - input data\n",
    "    Returns: sunpy.map - output data object\n",
    "    '''\n",
    "    helioproj_limb = sunpy.map.all_coordinates_from_map(sunpy_map).transform_to(\n",
    "        frames.Helioprojective(observer=sunpy_map.observer_coordinate))\n",
    "    rsun_hp_limb = sunpy_map.rsun_obs.value\n",
    "    distance_from_limb = np.sqrt(\n",
    "        helioproj_limb.Tx.value**2+helioproj_limb.Ty.value**2)/rsun_hp_limb\n",
    "    limb_cor_data = sunpy_map.data / limb_dark(distance_from_limb)\n",
    "    return sunpy.map.Map(limb_cor_data, sunpy_map.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE\n",
    "def normalize(sunpy_map, header_keyword='AVG_F_NO', NBINS=100):\n",
    "    '''\n",
    "    This function normalizes sunpy map\n",
    "    It first creates histogram of data\n",
    "    Finds maximum of histogram and divide whole dataset with that number\n",
    "    This is efectevly normalization to quiet sun\n",
    "\n",
    "    input:  sunpy_map (sunpy.map) - input data\n",
    "            header_keyword (string) - name of header keyword in which maximum of histogram will be written to \n",
    "                                      This allows users to later on, revert to unnormalized image, default is AVG_F_NO\n",
    "            NBINS (int) - How many bins you want for your histogram, default is 100\n",
    "    output: sunpy.map - output data object\n",
    "    '''\n",
    "    weights, bin_edges = np.histogram(\n",
    "        sunpy_map.data.flatten(), bins=NBINS, density=True)\n",
    "    # MAGIC I SAY!\n",
    "    # find maximum of histogram\n",
    "    k = (weights == np.max(weights)).nonzero()[0][0]\n",
    "    # find flux value for maximum of histogram\n",
    "    I_avg = (bin_edges[k+1]+bin_edges[k])/2\n",
    "    # update data\n",
    "    I_new = sunpy_map.data/I_avg\n",
    "    # create new keyword in header\n",
    "    # AVG_F_ON\n",
    "    # AVG_F_EN\n",
    "    sunpy_map.meta[header_keyword] = I_avg\n",
    "    # create new map\n",
    "    return sunpy.map.Map(I_new, sunpy_map.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_wrapper(sunpy_map, depth=5, model=\"keepsize\", activation=\"relu\", ntype=\"intensity\"):\n",
    "    '''\n",
    "    This procedures run enhance https://github.com/cdiazbas/enhance (it works only from my fork https://github.com/lzivadinovic/enhance)\n",
    "    on input sunpy map\n",
    "    Check source code for explanation of code and input parameters\n",
    "\n",
    "    input: sunpy_map (sunpy.map) - input data set\n",
    "    output: sunpy.map - output data object (enhanced)\n",
    "    '''\n",
    "    # if rtype is spmap, there is no need for output, it will return sunpy.map object (lzivadinovic/enhance fork - master branch)\n",
    "    out = enhance(inputFile=sunpy_map, depth=depth, model=model,\n",
    "                  activation=activation, ntype=ntype, output='1.fits', rtype='spmap')\n",
    "    out.define_network()\n",
    "    return out.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.abspath(\n",
    "    \"/home/lazar/Fak(s)/AF/prakse/SDSA/enhance/3481_11923_SHARP_CEA\")\n",
    "search_criterium = \"continuum\"\n",
    "sufix = \"_reduced\"\n",
    "data_list = sorted(glob.glob(os.path.join(\n",
    "    input_dir, \"*\"+search_criterium+\"*\")))\n",
    "# outdir\n",
    "output_dir = os.path.abspath(\n",
    "    \"/home/lazar/Fak(s)/AF/prakse/SDSA/enhance/3481_11923_SHARP_CEA_enhanced\")\n",
    "\n",
    "\n",
    "def master_wrap(filename):\n",
    "    '''\n",
    "    This function is just simple wrapper for all privided functions\n",
    "    \n",
    "    input: filename (string) -  fits file path that correction shoud be performed on\n",
    "    output: ofile (string) - string with path to new file\n",
    "    '''\n",
    "    # load data\n",
    "    sunpy_data = sunpy.map.Map(filename)\n",
    "    # correct map for limb\n",
    "    mid_data = correct_for_limb(sunpy_data)\n",
    "    # Normalize\n",
    "    mid_data = normalize(mid_data, header_keyword='AVG_F_ON')\n",
    "    # enhance\n",
    "    mid_data = enhance_wrapper(mid_data)\n",
    "    # normalize again, enhance can make mess with flux\n",
    "    mid_data = normalize(mid_data, header_keyword='AVG_F_EN')\n",
    "    # Create new filename\n",
    "    outfile = os.path.basename(filename).replace(\n",
    "        search_criterium, search_criterium+sufix)\n",
    "    ofile = os.path.join(output_dir, outfile)\n",
    "    # save map\n",
    "    mid_data.save(ofile)\n",
    "    return ofile\n",
    "\n",
    "# if you want to go crazy, you can do\n",
    "#normalize(enhance_wrapper(normalize(correct_for_limb(sunpy_data), header_keyword='AVG_F_ON')), header_keyword='AVG_F_EN').save(some_filename)\n",
    "# :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for i in data_list:\n",
    "        master_wrap(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
